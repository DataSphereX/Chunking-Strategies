{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Based Chunnking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# Test sentence-based chunking\n",
    "text = \"\"\"Artificial Intelligence is transforming the world. \n",
    "Businesses are leveraging AI for better decision-making. \n",
    "The healthcare industry uses AI to diagnose diseases more efficiently. \n",
    "Meanwhile, in education, AI is personalizing learning experiences. \n",
    "Despite its benefits, ethical concerns about AI are on the rise.\"\"\"\n",
    "\n",
    "# Tokenize sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paragraph Based Chunnking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraph_chunking(text):\n",
    "    \"\"\"\n",
    "    Chunk text into paragraphs based on newline characters.\n",
    "    \n",
    "    Args:\n",
    "    text (str): The input text containing multiple paragraphs.\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of paragraphs.\n",
    "    \"\"\"\n",
    "    # Split the text into paragraphs using two or more consecutive newlines\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "    return paragraphs\n",
    "\n",
    "# Chunk into paragraphs\n",
    "paragraphs = paragraph_chunking(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph Chunks:\n",
      "Paragraph 1: Artificial Intelligence is transforming the world. Businesses are leveraging AI for better decision-making. \n",
      "The healthcare industry uses AI to diagnose diseases more efficiently. Meanwhile, in education, AI is personalizing learning experiences. \n",
      "Despite its benefits, ethical concerns about AI are on the rise.\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Paragraph Chunks:\")\n",
    "for i, paragraph in enumerate(paragraphs, start=1):\n",
    "    print(f\"Paragraph {i}: {paragraph}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence & Paragraph Based Chunking in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Convert text into a Document object\n",
    "document = Document(page_content=text)\n",
    "\n",
    "# 1. Sentence-Based Chunking\n",
    "def sentence_based_chunking(document):\n",
    "    \"\"\"\n",
    "    Perform sentence-based chunking on the text.\n",
    "    \"\"\"\n",
    "    sentence_splitter = CharacterTextSplitter(separator=\". \", chunk_size=500, chunk_overlap=0)\n",
    "    sentences = sentence_splitter.split_text(document.page_content)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Paragraph-Based Chunking\n",
    "def paragraph_based_chunking(document):\n",
    "    \"\"\"\n",
    "    Perform paragraph-based chunking on the text.\n",
    "    \"\"\"\n",
    "    paragraph_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=500, chunk_overlap=0)\n",
    "    paragraphs = paragraph_splitter.split_text(document.page_content)\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence-Based Chunking:\n",
      "Sentence 1: Artificial Intelligence is transforming the world. Businesses are leveraging AI for better decision-making. \n",
      "The healthcare industry uses AI to diagnose diseases more efficiently. Meanwhile, in education, AI is personalizing learning experiences. \n",
      "Despite its benefits, ethical concerns about AI are on the rise.\n",
      "\n",
      "\n",
      "Paragraph-Based Chunking:\n",
      "Paragraph 1: Artificial Intelligence is transforming the world. Businesses are leveraging AI for better decision-making. \n",
      "The healthcare industry uses AI to diagnose diseases more efficiently. Meanwhile, in education, AI is personalizing learning experiences. \n",
      "Despite its benefits, ethical concerns about AI are on the rise.\n"
     ]
    }
   ],
   "source": [
    "# Perform sentence-based chunking\n",
    "sentence_chunks = sentence_based_chunking(document)\n",
    "print(\"Sentence-Based Chunking:\")\n",
    "for i, chunk in enumerate(sentence_chunks, start=1):\n",
    "    print(f\"Sentence {i}: {chunk}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Perform paragraph-based chunking\n",
    "paragraph_chunks = paragraph_based_chunking(document)\n",
    "print(\"Paragraph-Based Chunking:\")\n",
    "for i, chunk in enumerate(paragraph_chunks, start=1):\n",
    "    print(f\"Paragraph {i}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Convert text into a Document object\n",
    "document = Document(page_content=text)\n",
    "\n",
    "# 1. Sentence-Based Chunking\n",
    "def sentence_based_chunking(document):\n",
    "    \"\"\"\n",
    "    Perform sentence-based chunking on the text.\n",
    "    \"\"\"\n",
    "    sentence_splitter = CharacterTextSplitter(separator=\". \", chunk_size=500, chunk_overlap=0)\n",
    "    sentences = sentence_splitter.split_text(document.page_content)\n",
    "    return sentences\n",
    "\n",
    "\n",
    "# 2. Paragraph-Based Chunking\n",
    "def paragraph_based_chunking(document):\n",
    "    \"\"\"\n",
    "    Perform paragraph-based chunking on the text.\n",
    "    \"\"\"\n",
    "    paragraph_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size=500, chunk_overlap=0)\n",
    "    paragraphs = paragraph_splitter.split_text(document.page_content)\n",
    "    return paragraphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
