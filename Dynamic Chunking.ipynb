{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def dynamic_chunking(text, max_chunk_size):\n",
    "    \"\"\"\n",
    "    Splits text into dynamic chunks based on punctuation and semantic boundaries.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to chunk.\n",
    "        max_chunk_size (int): Maximum size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of dynamic chunks.\n",
    "    \"\"\"\n",
    "    sentences = re.split(r'(\\.|!|\\?)', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chunk_size:\n",
    "            current_chunk += sentence\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dynamic chunking adapts to text structure.', 'It improves context preservation!', 'This is great for NLP tasks.']\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "text = \"Dynamic chunking adapts to text structure. It improves context preservation! This is great for NLP tasks.\"\n",
    "chunks = dynamic_chunking(text, max_chunk_size=50)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 2 Chunks: ['Dynamic chunking ensures that text is processed adaptively.', 'This technique works especially well for conversational systems, summarization models, and document parsing', '. By analyzing the structure, we achieve better results!']\n"
     ]
    }
   ],
   "source": [
    "# Example Usage 2\n",
    "text2 = (\n",
    "    \"Dynamic chunking ensures that text is processed adaptively. This technique works especially well for conversational systems, \"\n",
    "    \"summarization models, and document parsing. By analyzing the structure, we achieve better results!\"\n",
    ")\n",
    "chunks2 = dynamic_chunking(text2, max_chunk_size=70)\n",
    "print(\"Example 2 Chunks:\", chunks2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/d0/a8/0a8f868615b7a30636b1d15b718e3ea9875bf0dccced03583477c2372495/langchain-0.3.14-py3-none-any.whl.metadata\n",
      "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/b1/03/d12b7c1d36fd80150c1d52e121614cf9377dac99e5497af8d8f5b2a8db64/SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.3 from https://files.pythonhosted.org/packages/fc/db/2192489a8a51b52e06627506f8ac8df69ee221de88ab9bdea77aa793aa6a/aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.29 (from langchain)\n",
      "  Obtaining dependency information for langchain-core<0.4.0,>=0.3.29 from https://files.pythonhosted.org/packages/95/4f/fe1de63f6fc1ac7af3ba4ae12d420af1a19f7893b5fcb72856b9fc67f650/langchain_core-0.3.29-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.29-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.3 (from langchain)\n",
      "  Obtaining dependency information for langchain-text-splitters<0.4.0,>=0.3.3 from https://files.pythonhosted.org/packages/a2/37/b2c971dfea62675f640e0dd5a078ca502885059276d21b7143cf1fe13e82/langchain_text_splitters-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading langchain_text_splitters-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
      "  Obtaining dependency information for langsmith<0.3,>=0.1.17 from https://files.pythonhosted.org/packages/12/91/e72d13f6b57a0ea9d884ab1d3388f544d7fe3354dbe1d4dd67678693a9fd/langsmith-0.2.10-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.2.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from langchain)\n",
      "  Obtaining dependency information for numpy<2,>=1.22.4 from https://files.pythonhosted.org/packages/3f/6b/5610004206cf7f8e7ad91c5a85a8c71b2f2f8051a0c0c4d5916b76d6cbb2/numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 3.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/b9/74/fbb6559de3607b3300b9be3cc64e97548d55678e44623db17820dbd20002/aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/89/aa/ab0f7891a01eeb2d2e338ae8fecbe57fcebea1a24dbb64d45801bfab481d/attrs-24.3.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-24.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/ca/8c/2ddffeb8b60a4bce3b196c32fcc30d8830d4615e7b492ec2071da801b8ad/frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/9f/0b/ad879847ecbf6d27e90a6eabb7eff6b62c129eefe617ea45eae7c1f0aead/multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/cf/59/7cc7037b295d5772eceb426358bb1b86e6cab4616d971bd74275395d100d/propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/ae/7b/8600250b3d89b625f1121d897062f629883c2f45339623b69b1747ec65fa/yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB 4.1 MB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/b5/15/90b3711f40d27aff80dd42c1eec2f0ed704a1fa47eef7120350e2797892d/orjson-3.10.13-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.10.13-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.3,>=0.1.17->langchain)\n",
      "  Obtaining dependency information for requests-toolbelt<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/3f/51/d4db610ef29373b879047326cbf6fa98b6c1969d6f6dc423279de2b1be2c/requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/12/da/b9ed5e310bb8b89661b80cbcd4db5a067903bbcd7fc854923f5ebb4144f0/greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\mentoring\\haystack\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain)\n",
      "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/71/92/5e77f98553e9e75130c78900d000368476aed74276eb8ae8796f65f00918/jsonpointer-3.0.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading langchain-0.3.14-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   --------------------------- ------------ 0.7/1.0 MB 14.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 12.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 10.6 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.11-cp311-cp311-win_amd64.whl (442 kB)\n",
      "   ---------------------------------------- 0.0/442.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 442.5/442.5 kB 13.5 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.29-py3-none-any.whl (411 kB)\n",
      "   ---------------------------------------- 0.0/411.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 411.6/411.6 kB 12.5 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.3.4-py3-none-any.whl (27 kB)\n",
      "Downloading langsmith-0.2.10-py3-none-any.whl (326 kB)\n",
      "   ---------------------------------------- 0.0/326.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 326.4/326.4 kB 19.8 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/15.8 MB 29.4 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.9/15.8 MB 14.0 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.6/15.8 MB 12.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 2.1/15.8 MB 13.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.7/15.8 MB 12.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 3.2/15.8 MB 12.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.8/15.8 MB 12.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 4.3/15.8 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 4.8/15.8 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 5.3/15.8 MB 11.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 5.9/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.4/15.8 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.5/15.8 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 7.0/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.5/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 8.0/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 8.6/15.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.1/15.8 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 9.7/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 10.3/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.8/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 11.4/15.8 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.9/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.4/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 12.9/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.0/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.5/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 15.0/15.8 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.5/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.1 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.2/2.1 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.7/2.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.3.0-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.4/63.4 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading frozenlist-1.5.0-cp311-cp311-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.6/51.6 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "   ---------------------------------------- 0.0/298.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 298.9/298.9 kB 9.3 MB/s eta 0:00:00\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.13-cp311-cp311-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.1/135.1 kB 7.8 MB/s eta 0:00:00\n",
      "Downloading propcache-0.2.1-cp311-cp311-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.4/44.4 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "   ---------------------------------------- 0.0/54.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 54.5/54.5 kB ? eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp311-cp311-win_amd64.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/91.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 91.0/91.0 kB ? eta 0:00:00\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Installing collected packages: propcache, orjson, numpy, multidict, jsonpointer, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.1\n",
      "    Uninstalling numpy-2.2.1:\n",
      "      Successfully uninstalled numpy-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'D:\\\\Mentoring\\\\HayStack\\\\venv\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-43e11ff0749b8cbe0a615c9cf6737e0e.dll'\n",
      "Check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Sample text\u001b[39;00m\n\u001b[0;32m      4\u001b[0m text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDynamic chunking ensures that text is processed adaptively. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis technique works especially well for conversational systems, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummarization models, and document parsing. By analyzing the structure, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe achieve better results!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Sample text\n",
    "text = (\n",
    "    \"Dynamic chunking ensures that text is processed adaptively. \"\n",
    "    \"This technique works especially well for conversational systems, \"\n",
    "    \"summarization models, and document parsing. By analyzing the structure, \"\n",
    "    \"we achieve better results!\"\n",
    ")\n",
    "\n",
    "# Define a RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,            # Maximum size of each chunk\n",
    "    chunk_overlap=20,          # Overlap between chunks for context retention\n",
    "    separators=[\"\\n\\n\", \". \", \"! \", \"? \"]  # Dynamic boundary indicators\n",
    ")\n",
    "\n",
    "# Apply the splitter\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# Output the dynamic chunks\n",
    "for i, chunk in enumerate(chunks, 1):\n",
    "    print(f\"Chunk {i}: {chunk}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
